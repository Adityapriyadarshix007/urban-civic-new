{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206712aa-0731-497d-8285-c29eac3d18fa",
   "metadata": {},
   "source": [
    "# Export ML Outputs for Dashboard Integration\n",
    "\n",
    "This notebook converts processed ML outputs (CSV files) into\n",
    "JSON format for frontend dashboard consumption.\n",
    "\n",
    "This notebook is run once after model execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2e325bac-5e76-4c81-9153-9848a67d742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "priority_results.json successfully exported to public/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV (relative to ml/)\n",
    "df = pd.read_csv(\"data/processed/priority_results.csv\")\n",
    "\n",
    "# Convert to JSON records\n",
    "records = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Export to frontend public folder (relative to ml/)\n",
    "with open(\"../public/priority_results.json\", \"w\") as f:\n",
    "    json.dump(records, f, indent=2)\n",
    "\n",
    "print(\"priority_results.json successfully exported to public/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3022875-5b05-4baa-adf1-af67828083a0",
   "metadata": {},
   "source": [
    "## Dashboard Data Export (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6893c3c5-8795-4cd0-ab4e-3af9cb4fdf1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hotspot_summary.json exported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = Path(\"../../public\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load hotspot summary\n",
    "hotspot_df = pd.read_csv(\"data/processed/hotspot_summary.csv\")\n",
    "\n",
    "hotspot_json = hotspot_df.to_dict(orient=\"records\")\n",
    "\n",
    "with open(output_dir / \"hotspot_summary.json\", \"w\") as f:\n",
    "    json.dump(hotspot_json, f, indent=2)\n",
    "\n",
    "print(\"hotspot_summary.json exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce45b1e5-d959-41bb-90dc-69b57d5f21c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_priority_matrix.json exported\n"
     ]
    }
   ],
   "source": [
    "# Load priority results\n",
    "priority_df = pd.read_csv(\"data/processed/priority_results.csv\")\n",
    "\n",
    "# If category name is not present, merge from original dataset\n",
    "raw_df = pd.read_csv(\"data/raw/urban_civic_reports_synthetic.csv\")\n",
    "\n",
    "merged_df = priority_df.merge(\n",
    "    raw_df[['ID', 'Category']],\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "category_priority = pd.crosstab(\n",
    "    merged_df['Category'],\n",
    "    merged_df['priority_level']\n",
    ")\n",
    "\n",
    "category_priority_json = {\n",
    "    \"categories\": category_priority.index.tolist(),\n",
    "    \"priorities\": category_priority.columns.tolist(),\n",
    "    \"matrix\": category_priority.values.tolist()\n",
    "}\n",
    "\n",
    "with open(output_dir / \"category_priority_matrix.json\", \"w\") as f:\n",
    "    json.dump(category_priority_json, f, indent=2)\n",
    "\n",
    "print(\"category_priority_matrix.json exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a21dbc5b-52e4-4c67-ac85-93e51d1836d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_score_bins.json exported\n"
     ]
    }
   ],
   "source": [
    "# Create bins for risk score\n",
    "bins = [0, 0.3, 0.5, 0.7, 1.0]\n",
    "labels = [\"Very Low\", \"Low\", \"Medium\", \"High\"]\n",
    "\n",
    "priority_df['risk_bin'] = pd.cut(\n",
    "    priority_df['risk_score'],\n",
    "    bins=bins,\n",
    "    labels=labels\n",
    ")\n",
    "\n",
    "risk_bins = priority_df['risk_bin'].value_counts().sort_index()\n",
    "\n",
    "risk_bins_json = [\n",
    "    {\"bin\": str(bin_name), \"count\": int(count)}\n",
    "    for bin_name, count in risk_bins.items()\n",
    "]\n",
    "\n",
    "with open(output_dir / \"risk_score_bins.json\", \"w\") as f:\n",
    "    json.dump(risk_bins_json, f, indent=2)\n",
    "\n",
    "print(\"risk_score_bins.json exported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d7f18-955b-4e0b-b9a7-917bf09046fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (Anaconda)",
   "language": "python",
   "name": "py13_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
